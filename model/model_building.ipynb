{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"data.csv\")  # or full path / URL: \"https://raw.githubusercontent.com/.../data.csv\"\n",
    "print(df.head())\n",
    "print(df.info())  # Check no missing values (this dataset has none!)\n",
    "\n",
    "# Keep only allowed columns\n",
    "df = df[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'diagnosis']]\n",
    "\n",
    "# 2. Preprocessing\n",
    "# Target encoding: M=1 (malignant), B=0 (benign)\n",
    "le = LabelEncoder()\n",
    "df['diagnosis'] = le.fit_transform(df['diagnosis'])  # M → 1, B → 0\n",
    "\n",
    "# Features & target\n",
    "features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean']\n",
    "X = df[features]\n",
    "y = df['diagnosis']\n",
    "\n",
    "# Feature scaling (mandatory for Logistic Regression stability, KNN, SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=features)\n",
    "\n",
    "# 3. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 4. Model - Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Expected: ~0.94–0.97 accuracy with these features\n",
    "\n",
    "# 6. Save model + scaler + label encoder (if needed)\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "joblib.dump(model, \"model/breast_cancer_model.joblib\")\n",
    "joblib.dump(scaler, \"model/scaler.joblib\")\n",
    "joblib.dump(le, \"model/label_encoder.joblib\")  # Optional but safe\n",
    "\n",
    "print(\"Model saved!\")\n",
    "\n",
    "# 7. Demonstrate reload\n",
    "loaded_model = joblib.load(\"model/breast_cancer_model.joblib\")\n",
    "loaded_scaler = joblib.load(\"model/scaler.joblib\")\n",
    "\n",
    "# Example new data (must scale!)\n",
    "sample = pd.DataFrame({\n",
    "    'radius_mean': [17.99],\n",
    "    'texture_mean': [10.38],\n",
    "    'perimeter_mean': [122.8],\n",
    "    'area_mean': [1001.0],\n",
    "    'smoothness_mean': [0.11840]\n",
    "})\n",
    "sample_scaled = loaded_scaler.transform(sample)\n",
    "pred = loaded_model.predict(sample_scaled)[0]\n",
    "print(\"Prediction:\", \"Malignant\" if pred == 1 else \"Benign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create the model folder if it doesn't exist\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Save the model inside the model/ folder (matches assignment structure)\n",
    "model_path = \"model/breast_cancer_model.pkl\"\n",
    "\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f\"Model saved successfully to: {os.path.abspath(model_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b55fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open(\"model/scaler.pkl\", \"wb\"))\n",
    "# or if using joblib: joblib.dump(scaler, \"model/scaler.joblib\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
